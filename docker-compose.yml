version: '3.7'

x-spark-common: &spark-common
  image: bitnami/spark:latest
  volumes:
    - ./jobs:/opt/bitnami/spark/jobs
    - ./data:/opt/bitnami/spark/data
    - ./resources:/opt/bitnami/spark/resources
  environment:
    TZ: "Asia/Seoul"
  networks:
    - default-network

x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile
  env_file:
    - airflow.env
  volumes:
    - ./jobs:/opt/airflow/jobs
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./resources:/opt/bitnami/spark/resources
    - ./data:/opt/bitnami/spark/data
    - /var/run/docker.sock:/var/run/docker.sock  # Docker 소켓 마운트 추가
  depends_on:
    - postgres
  environment:
    TZ: "Asia/Seoul"
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__CORE__PLUGINS_FOLDER: /opt/airflow/plugins
  networks:
    - default-network

services:
  # Spark Master
  spark-master:
    <<: *spark-common
    hostname: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master
    expose:
      - "7077"
    ports:
      - "9090:8080"
      - "7077:7077"
      - "4444:4040"

  # Spark Worker 1
  spark-worker-1:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

  # Spark Worker 2
  spark-worker-2:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

  # Jupyter Notebook with Spark
  jupyter-spark:
    build:
      context: .
      dockerfile: jupyter/Dockerfile
    networks:
      - default-network
    ports:
      - "8887:8888"
      - "4040-4080:4040-4080"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./jobs:/home/jovyan/jobs
      - ./resources:/home/jovyan/resources
    environment:
      - JUPYTER_TOKEN=password

  # Elasticsearch
  es:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.4.3
    container_name: es
    networks:
      - default-network
    environment:
      - node.name=es
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
      - DATA_DIR=/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - es_data:/usr/share/elasticsearch/data  # 네임드 볼륨 사용
    ports:
      - 9200:9200
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.4.3
    networks:
      - default-network
    environment:
      - ELASTICSEARCH_HOSTS=http://es:9200
    ports:
      - 5601:5601
    depends_on:
      - es

  # PostgreSQL for Airflow
  postgres:
    image: postgres:14.0
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data  # 네임드 볼륨 사용
    networks:
      - default-network

  # Grafana
  grafana:
    image: grafana/grafana-enterprise
    container_name: grafana
    restart: unless-stopped
    ports:
      - '4000:3000'
    volumes:
      - grafana-storage:/var/lib/grafana  # 네임드 볼륨 사용
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  # 기본 관리자 비밀번호 설정
      - GF_SECURITY_ADMIN_USER=admin      # 기본 관리자 사용자 설정
      - GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS=grafana-elasticsearch-datasource
    networks:
      - default-network
    depends_on:
      - es  # Elasticsearch가 먼저 시작되도록 설정

  # Airflow Webserver
  webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8081:8080"
    depends_on:
      - scheduler

  # Airflow Scheduler
  scheduler:
    <<: *airflow-common
    command: bash -c "airflow db init && airflow db migrate && airflow users create --username airflow --firstname airflow --lastname airflow --role Admin --email airflow@gmail.com --password airflow && airflow scheduler"

volumes:
  postgres_data:
    driver: local
  grafana-storage:
    driver: local
  es_data:  # 네임드 볼륨으로 Elasticsearch 데이터 영구 저장
    driver: local

networks:
  default-network:
    driver: bridge
